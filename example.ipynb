{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage for `mix_gamma_vi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mix_gamma_vi import mix_gamma_vi\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10000 data from a mixture of gamma two gamma distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "pi_true = [0.5, 0.5]\n",
    "a_true  = [20,  80 ]\n",
    "B_true  = [20,  40 ]\n",
    "\n",
    "mix_gamma = tfp.distributions.MixtureSameFamily(\n",
    "    mixture_distribution=tfp.distributions.Categorical(probs=pi_true),\n",
    "    components_distribution=tfp.distributions.Gamma(concentration=a_true, rate=B_true))\n",
    "\n",
    "x = mix_gamma.sample(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference Under the Shape-Mean Parameterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defualt parameterisation for the function `mix_gamma_vi` is the mean-shape parameterisation under which the variational approximations to the posterior are\n",
    "\n",
    "$$ q^*(\\mathbf{\\pi}) = \\mathrm{Dirichlet} \\left( \\zeta_1, ..., \\zeta_K \\right) ,   $$\n",
    "$$ q^*(\\alpha_k) = \\mathcal{N}(\\hat{\\alpha}_k, \\sigma_j^2) .  $$\n",
    "$$ q^* (\\mu_k) =  \\operatorname{Inv-Gamma} \\left( \\gamma_k, \\lambda_k \\right) ,   $$\n",
    "The product approximates the joint posterior\n",
    "$$ p(\\mathbf{\\pi}, \\mathbf{\\alpha}, \\mathbf{\\mu} \\mid \\mathbf{x}) \\approx q^*(\\mathbf{\\pi}) \\prod_{k=1}^K q^*(\\alpha_k) q^*(\\mu_k). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2672, shape=(1, 2), dtype=float32, numpy=array([[0.49894944, 0.5010506 ]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: id=2679, shape=(1, 2), dtype=float32, numpy=array([[0.9940482, 1.9919776]], dtype=float32)>,\n",
       " 'alpha': <tf.Tensor: id=2683, shape=(1, 2), dtype=float32, numpy=array([[20.416248, 78.11654 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model\n",
    "fit = mix_gamma_vi(x, 2)\n",
    "\n",
    "# Get the fitted distribution\n",
    "distribution = fit.distribution()\n",
    "\n",
    "# Get the means of the parameters under the fitted posterior\n",
    "distribution.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2693, shape=(1, 2), dtype=float32, numpy=array([[0.00499924, 0.00499924]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: id=2706, shape=(1, 2), dtype=float32, numpy=array([[0.00311455, 0.003184  ]], dtype=float32)>,\n",
       " 'alpha': <tf.Tensor: id=2710, shape=(1, 2), dtype=float32, numpy=array([[0.4087547, 1.5606917]], dtype=float32)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference Under the Shape-Rate Parameterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional parameterisation for gamma distribution is the shape-rate parameterisation which this package also supports (although it is not recommended). In this case, the variational approximations to the posterior are\n",
    "\n",
    "$$ q^*(\\mathbf{\\pi}) = \\mathrm{Dirichlet} \\left( \\zeta_1, ..., \\zeta_K \\right) ,   $$\n",
    "$$ q^*(\\alpha_k) = \\mathcal{N}(\\hat{\\alpha}_k, \\sigma_k^2) .  $$\n",
    "$$ q^* (\\beta_k) =  \\operatorname{Gamma} \\left( \\gamma_j, \\lambda_j \\right) ,   $$\n",
    "The product approximates the joint posterior\n",
    "$$ p(\\mathbf{\\pi}, \\mathbf{\\alpha}, \\mathbf{\\beta} \\mid \\mathbf{x}) \\approx q^*(\\mathbf{\\pi}) \\prod_{k=1}^K q^*(\\alpha_k) q^*(\\beta_k) . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2721, shape=(1, 2), dtype=float64, numpy=array([[0.49918154, 0.50081846]])>,\n",
       " 'beta': <tf.Tensor: id=2728, shape=(1, 2), dtype=float64, numpy=array([[0.04899512, 0.02543706]])>,\n",
       " 'alpha': <tf.Tensor: id=2732, shape=(1, 2), dtype=float64, numpy=array([[20.29621189, 78.31683818]])>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model\n",
    "fit = mix_gamma_vi(x, 2, parameterisation=\"shape-rate\")\n",
    "\n",
    "# Get the fitted distribution\n",
    "distribution = fit.distribution()\n",
    "\n",
    "# Get the means of the parameters under the fitted posterior\n",
    "distribution.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2742, shape=(1, 2), dtype=float64, numpy=array([[0.00499924, 0.00499924]])>,\n",
       " 'beta': <tf.Tensor: id=2755, shape=(1, 2), dtype=float64, numpy=array([[1.53936081e-04, 4.06161258e-05]])>,\n",
       " 'alpha': <tf.Tensor: id=2759, shape=(1, 2), dtype=float64, numpy=array([[0.06292623, 0.12475457]])>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the standard deviation of $\\mathbf{\\alpha}$ under the shape-rate parameterisation is much lower than it is under the shape-mean parameterisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
