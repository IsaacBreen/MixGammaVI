{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage for `mix_gamma_vi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mix_gamma_vi import mix_gamma_vi\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10000 data from a mixture of gamma two gamma distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "pi_true = [0.5, 0.5]\n",
    "a_true  = [20,  80 ]\n",
    "B_true  = [20,  40 ]\n",
    "\n",
    "mix_gamma = tfp.distributions.MixtureSameFamily(\n",
    "    mixture_distribution=tfp.distributions.Categorical(probs=pi_true),\n",
    "    components_distribution=tfp.distributions.Gamma(concentration=a_true, rate=B_true))\n",
    "\n",
    "x = mix_gamma.sample(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference Under the Shape-Mean Parameterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defualt parameterisation for the function `mix_gamma_vi` is the mean-shape parameterisation under which the variational approximations to the posterior are\n",
    "\n",
    "$$ q^*(\\mathbf{\\pi}) = \\left( \\zeta_1, ..., \\zeta_K \\right)   $$\n",
    "\n",
    "$$ q^*(\\mathbf{\\pi}) = \\mathrm{Dirichlet} \\left( \\zeta_1, ..., \\zeta_K \\right) ,   $$\n",
    "$$ q^*(\\alpha_k) = \\mathcal{N}(\\hat{\\alpha}_k, \\sigma_j^2) ,$$\n",
    "$$ q^* (\\mu_k) =  \\operatorname{Inv-Gamma} \\left( \\gamma_k, \\lambda_k \\right) .   $$\n",
    "The product approximates the joint posterior\n",
    "$$ p(\\mathbf{\\pi}, \\mathbf{\\alpha}, \\mathbf{\\mu} \\mid \\mathbf{x}) \\approx q^*(\\mathbf{\\pi}) \\prod_{k=1}^K q^*(\\alpha_k) q^*(\\mu_k). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=1324, shape=(1, 2), dtype=float32, numpy=array([[0.4959155 , 0.50408447]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: id=1331, shape=(1, 2), dtype=float32, numpy=array([[1.0062267, 2.0021513]], dtype=float32)>,\n",
       " 'alpha': <tf.Tensor: id=1335, shape=(1, 2), dtype=float32, numpy=array([[19.765982, 80.58321 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model\n",
    "fit = mix_gamma_vi(x, 2)\n",
    "\n",
    "# Get the fitted distribution\n",
    "distribution = fit.distribution()\n",
    "\n",
    "# Get the means of the parameters under the fitted posterior\n",
    "distribution.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=1345, shape=(1, 2), dtype=float32, numpy=array([[0.00499908, 0.00499908]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: id=1358, shape=(1, 2), dtype=float32, numpy=array([[0.00321394, 0.0031414 ]], dtype=float32)>,\n",
       " 'alpha': <tf.Tensor: id=1362, shape=(1, 2), dtype=float32, numpy=array([[0.39694458, 1.6051203 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference Under the Shape-Rate Parameterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional parameterisation for gamma distribution is the shape-rate parameterisation which this package also supports (although it is not recommended). In this case, the variational approximations to the posterior are\n",
    "\n",
    "$$ q^*(\\mathbf{\\pi}) = \\mathrm{Dirichlet} \\left( \\zeta_1, ..., \\zeta_K \\right) ,   $$\n",
    "$$ q^*(\\alpha_k) = \\mathcal{N}(\\hat{\\alpha}_k, \\sigma_k^2) ,  $$\n",
    "$$ q^* (\\beta_k) =  \\operatorname{Gamma} \\left( \\gamma_j, \\lambda_j \\right) .   $$\n",
    "The product approximates the joint posterior\n",
    "$$ p(\\mathbf{\\pi}, \\mathbf{\\alpha}, \\mathbf{\\beta} \\mid \\mathbf{x}) \\approx q^*(\\mathbf{\\pi}) \\prod_{k=1}^K q^*(\\alpha_k) q^*(\\beta_k) . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2435, shape=(1, 2), dtype=float64, numpy=array([[0.49586246, 0.50413754]])>,\n",
       " 'beta': <tf.Tensor: id=2442, shape=(1, 2), dtype=float64, numpy=array([[0.05108236, 0.0249591 ]])>,\n",
       " 'alpha': <tf.Tensor: id=2446, shape=(1, 2), dtype=float64, numpy=array([[19.69911649, 80.21602851]])>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model\n",
    "fit = mix_gamma_vi(x, 2, parameterisation=\"shape-rate\")\n",
    "\n",
    "# Get the fitted distribution\n",
    "distribution = fit.distribution()\n",
    "\n",
    "# Get the means of the parameters under the fitted posterior\n",
    "distribution.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: id=2456, shape=(1, 2), dtype=float64, numpy=array([[0.00499908, 0.00499908]])>,\n",
       " 'beta': <tf.Tensor: id=2469, shape=(1, 2), dtype=float64, numpy=array([[1.63451684e-04, 3.92490419e-05]])>,\n",
       " 'alpha': <tf.Tensor: id=2473, shape=(1, 2), dtype=float64, numpy=array([[0.06197073, 0.12626589]])>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the standard deviation of $\\mathbf{\\alpha}$ under the shape-rate parameterisation is much lower than it is under the shape-mean parameterisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
